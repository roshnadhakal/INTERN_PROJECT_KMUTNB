{
  "vectorization_methods": [
    "tfidf",
    "tokenizer",
    "sequences",
    "padded_sequences",
    "embedding_matrix",
    "embedding_info"
  ],
  "vocab_size": 33,
  "max_len": 100,
  "timestamp": "2025-07-21T09:09:53.989013"
}